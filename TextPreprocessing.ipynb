{"cells":[{"cell_type":"markdown","metadata":{"id":"bXTFLI4NF-LR"},"source":["## Этапы (простой) обработки текста\n","\n","<img src=\"images/textm.png\">"]},{"cell_type":"markdown","metadata":{"id":"rgf1SvTRF-LS"},"source":["\n","## Декодирование\n","\n","\n","**Def.**  \n","перевод последовательности байт в последовательность символов\n","\n","* Распаковка  \n","*plain/.zip/.gz/...*\n","* Кодировка  \n","*ASCII/utf-8/Windows-1251/...*\n","* Формат  \n","*csv/xml/json/doc...*\n","\n","Кроме того: что такое документ?\n","\n"]},{"cell_type":"markdown","metadata":{"id":"I3xU0-PjF-LS"},"source":["## Разбиение на токены\n","**Def.**  \n","разбиение последовательности символов на части (токены), возможно, исключая из рассмотрения некоторые символы  \n","Наивный подход: разделить строку пробелами и выкинуть знаки препинания  \n","\n","\n","*Трисия любила Нью-Йорк, поскольку любовь к Нью-Йорку могла положительно повлиять на ее карьеру.*  \n","\n","\n","**Проблемы:**  \n","* example@example.com, 127.0.0.1\n","* С++, C#\n","* York University vs New York University\n","* Зависимость от языка (“Lebensversicherungsgesellschaftsangestellter”, “l’amour”)\n","Альтернатива: n-граммы"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: nltk in c:\\users\\vsevolod.volkov\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (3.7)\n","Requirement already satisfied: click in c:\\users\\vsevolod.volkov\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nltk) (8.1.3)\n","Requirement already satisfied: tqdm in c:\\users\\vsevolod.volkov\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nltk) (4.64.0)\n","Requirement already satisfied: joblib in c:\\users\\vsevolod.volkov\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nltk) (1.1.0)\n","Requirement already satisfied: regex>=2021.8.3 in c:\\users\\vsevolod.volkov\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nltk) (2022.8.17)\n","Requirement already satisfied: colorama in c:\\users\\vsevolod.volkov\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from click->nltk) (0.4.5)\n","Note: you may need to restart the kernel to use updated packages.\n"]},{"name":"stderr","output_type":"stream","text":["WARNING: You are using pip version 22.0.4; however, version 22.2.2 is available.\n","You should consider upgrading via the 'c:\\Users\\vsevolod.volkov\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"]}],"source":["%pip install nltk"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1719,"status":"ok","timestamp":1631048074715,"user":{"displayName":"Михаил Баранов","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjVV46Gpmty8si64xPQTsh_aZMsXJnF8ADGg9xOTg=s64","userId":"05195714544608108975"},"user_tz":-180},"id":"BTJ5nrYYF-LT","outputId":"7d3bd7ab-d9ec-4f33-98df-2d1a4688b602"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package stopwords to\n","[nltk_data]     C:\\Users\\vsevolod.volkov\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Unzipping corpora\\stopwords.zip.\n"]},{"data":{"text/plain":["True"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["import nltk\n","nltk.download('stopwords')"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":50,"status":"ok","timestamp":1631048074720,"user":{"displayName":"Михаил Баранов","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjVV46Gpmty8si64xPQTsh_aZMsXJnF8ADGg9xOTg=s64","userId":"05195714544608108975"},"user_tz":-180},"id":"Olg2Ah-SF-LV","outputId":"33cd3cf8-dfdf-4f0f-822b-a322096f35b2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Трисия\n","любила\n","Нью\n","-\n","Йорк\n",",\n","поскольку\n","любовь\n","к\n","Нью\n","-\n","Йорку\n","могла\n","положительно\n","повлиять\n","на\n","ее\n","карьеру\n",".\n"]}],"source":["from nltk.tokenize import RegexpTokenizer\n","\n","\n","s = \"Трисия любила Нью-Йорк, поскольку любовь к Нью-Йорку могла положительно повлиять на ее карьеру.\"\n","\n","tokenizer = RegexpTokenizer(\"\\w+|[^\\w\\s]+\")\n","for t in tokenizer.tokenize(s): \n","    print(t)"]},{"cell_type":"markdown","metadata":{"id":"buEIu-_CF-LV"},"source":["## Стоп-слова\n","**Def.**  \n","Наиболее частые слова в языке, не содержащие никакой информации о содержании текста\n","\n"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"uZL-XwB9F-LW"},"outputs":[{"name":"stdout","output_type":"stream","text":["и в во не что он на я с со как а то все она так его но да ты к у же вы за бы по только ее мне было вот от меня еще нет о из ему теперь когда даже ну вдруг ли если уже или ни быть был него до вас нибудь опять уж вам ведь там потом себя ничего ей может они тут где есть надо ней для мы тебя их чем была сам чтоб без будто чего раз тоже себе под будет ж тогда кто этот того потому этого какой совсем ним здесь этом один почти мой тем чтобы нее сейчас были куда зачем всех никогда можно при наконец два об другой хоть после над больше тот через эти нас про всего них какая много разве три эту моя впрочем хорошо свою этой перед иногда лучше чуть том нельзя такой им более всегда конечно всю между\n"]}],"source":["from nltk.corpus import stopwords\n","\n","\n","print(\" \".join(stopwords.words(\"russian\")))"]},{"cell_type":"markdown","metadata":{"id":"aXzzCadWF-LW"},"source":["Проблема: “To be or not to be\""]},{"cell_type":"markdown","metadata":{"id":"M2vMM3qnF-LW"},"source":["## Нормализация\n","**Def.**  \n","Приведение токенов к единому виду для того, чтобы избавиться от поверхностной разницы в написании  \n","\n","Подходы  \n","* сформулировать набор правил, по которым преобразуется токен  \n","Нью-Йорк → нью-йорк → ньюйорк → ньюиорк\n","* явно хранить связи между токенами (WordNet – Princeton)  \n","машина → автомобиль, Windows 6→ window"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"INpfX6wqF-LX"},"outputs":[{"name":"stdout","output_type":"stream","text":["нью-йорк\n"]}],"source":["s = \"Нью-Йорк\"\n","s1 = s.lower()\n","print(s1)"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"Wa4NDjrIF-LX"},"outputs":[{"name":"stdout","output_type":"stream","text":["ньюйорк\n"]}],"source":["import re\n","s2 = re.sub(r\"\\W\", \"\", s1, flags=re.U)\n","print(s2)"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"ESECQgj2F-LY"},"outputs":[{"name":"stdout","output_type":"stream","text":["ньюиорк\n"]}],"source":["s3 = re.sub(r\"й\", u\"и\", s2, flags=re.U)\n","print(s3)"]},{"cell_type":"markdown","metadata":{"id":"mxgUV4UbF-LY"},"source":["## Стемминг и Лемматизация\n","**Def.**  \n","Приведение грамматических форм слова и однокоренных слов к единой основе (lemma):\n","* Stemming – с помощью простых эвристических правил\n","  * Porter (Cambridge – 1980)\n","        5 этапов, на каждом применяется набор правил, таких как\n","            sses → ss (caresses → caress)\n","            ies → i (ponies → poni)\n","\n","  * Lovins (1968)\n","  * Paice (1990)\n","  * другие\n","* Lemmatization – с использованием словарей и морфологического анализа\n"]},{"cell_type":"markdown","metadata":{"id":"RgDqrYkdF-LZ"},"source":["## Стемминг"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"fgpAl1MJF-LZ"},"outputs":[{"name":"stdout","output_type":"stream","text":["token\n","stem\n","авиац\n","национальн\n"]}],"source":["from nltk.stem.snowball import PorterStemmer\n","from nltk.stem.snowball import RussianStemmer\n","\n","\n","s = PorterStemmer()\n","print(s.stem(\"Tokenization\"))\n","print(s.stem(\"stemming\"))\n","\n","r = RussianStemmer()\n","print(r.stem(\"Авиация\"))\n","print(r.stem(\"национальный\"))"]},{"cell_type":"markdown","metadata":{"id":"xfUJXVE4F-LZ"},"source":["**Наблюдение**  \n","для сложных языков лучше подходит лемматизация"]},{"cell_type":"markdown","metadata":{"id":"6nwjaX0zF-La"},"source":["## Лемматизация"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"Bq8bFg_DF-La"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting pymorphy2\n","  Using cached pymorphy2-0.9.1-py3-none-any.whl (55 kB)\n","Collecting dawg-python>=0.7.1\n","  Using cached DAWG_Python-0.7.2-py2.py3-none-any.whl (11 kB)\n","Collecting docopt>=0.6\n","  Using cached docopt-0.6.2.tar.gz (25 kB)\n","  Preparing metadata (setup.py): started\n","  Preparing metadata (setup.py): finished with status 'done'\n","Collecting pymorphy2-dicts-ru<3.0,>=2.4\n","  Using cached pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl (8.2 MB)\n","Using legacy 'setup.py install' for docopt, since package 'wheel' is not installed.\n","Installing collected packages: pymorphy2-dicts-ru, docopt, dawg-python, pymorphy2\n","  Running setup.py install for docopt: started\n","  Running setup.py install for docopt: finished with status 'done'\n","Successfully installed dawg-python-0.7.2 docopt-0.6.2 pymorphy2-0.9.1 pymorphy2-dicts-ru-2.4.417127.4579844\n","Note: you may need to restart the kernel to use updated packages.\n"]},{"name":"stderr","output_type":"stream","text":["WARNING: You are using pip version 22.0.4; however, version 22.2.2 is available.\n","You should consider upgrading via the 'c:\\Users\\vsevolod.volkov\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"]}],"source":["%pip install pymorphy2"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"qSekO34BF-La"},"outputs":[{"name":"stdout","output_type":"stream","text":["думать\n","[Parse(word='думающему', tag=OpencorporaTag('PRTF,impf,intr,pres,actv masc,sing,datv'), normal_form='думать', score=0.25, methods_stack=((DictionaryAnalyzer(), 'думающему', 15, 15),)), Parse(word='думающему', tag=OpencorporaTag('PRTF,impf,intr,pres,actv neut,sing,datv'), normal_form='думать', score=0.25, methods_stack=((DictionaryAnalyzer(), 'думающему', 15, 29),)), Parse(word='думающему', tag=OpencorporaTag('PRTF,impf,tran,pres,actv masc,sing,datv'), normal_form='думать', score=0.25, methods_stack=((DictionaryAnalyzer(), 'думающему', 1399, 15),)), Parse(word='думающему', tag=OpencorporaTag('PRTF,impf,tran,pres,actv neut,sing,datv'), normal_form='думать', score=0.25, methods_stack=((DictionaryAnalyzer(), 'думающему', 1399, 29),))]\n"]}],"source":["import pymorphy2\n","\n","\n","morph = pymorphy2.MorphAnalyzer()\n","print(morph.parse(\"думающему\")[0].normal_form)\n","print(morph.parse(\"думающему\"))"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pymorphy2.analyzer.Parse'>\n"]}],"source":["print(type(morph.parse(\"думающему\")[0]))"]},{"cell_type":"markdown","metadata":{"id":"xc6Z0UY9F-La"},"source":["## Heaps' law\n","Эмпирическая закономерность в лингвистике, описывающая распределение числа уникальных слов в документе (или наборе документов) как функцию от его длины.\n","\n","$$\n","M = k T^\\beta, \\;M \\text{ -- размер словаря}, \\; T \\text{ -- количество слов в корпусе}\n","$$\n","$$\n","30 \\leq k \\leq 100, \\; b \\approx 0.5\n","$$\n","\n","<img src=\"images/dim.png\">\n","<img src=\"images/heaps.png\">"]},{"cell_type":"markdown","metadata":{"id":"FzDJlw5OF-Lb"},"source":["## Представление документов\n","**Boolean Model.** Присутствие или отсутствие слова в документе  \n","**Bag of Words.** Порядок токенов не важен  \n","\n","*Погода была ужасная, принцесса была прекрасная.\n","Или все было наоборот?*\n","\n","Координаты\n","* Мультиномиальные: количество токенов в документе\n","* Числовые: взвешенное количество токенов в документе"]},{"cell_type":"markdown","metadata":{"id":"7TlHOiiCF-Lb"},"source":["## Zipf's law\n","Эмпирическая закономерность распределения частоты слов естественного языка\n","\n","$t_1, \\ldots, t_N$ - токены, отранжированные по убыванию частоты\n","   \t\n","$f_1, \\dots, f_N$ - соответствующие частоты\n","\n","**Закон Ципфа**\n","\t$$\n","\tf_i = \\frac{c}{i^k}\n","\t$$\t\n","\t\n","\tЧто еще? Посещаемость сайтов, количество друзей, население городов...\n","<img src=\"images/zipf.png\">\n"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: pip in c:\\users\\vsevolod.volkov\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (22.0.4)\n","Collecting pip\n","  Using cached pip-22.2.2-py3-none-any.whl (2.0 MB)\n","Installing collected packages: pip\n","  Attempting uninstall: pip\n","    Found existing installation: pip 22.0.4\n","    Uninstalling pip-22.0.4:\n","      Successfully uninstalled pip-22.0.4\n","Successfully installed pip-22.2.2\n","Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["# %pip install pandas\n","%pip install --upgrade pip"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>мама</td>\n","      <td>мыла</td>\n","      <td>раму</td>\n","      <td>мылом</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>у</td>\n","      <td>попа</td>\n","      <td>была</td>\n","      <td>собака</td>\n","      <td>он</td>\n","      <td>её</td>\n","      <td>любил</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      0     1     2       3     4     5      6\n","0  мама  мыла  раму   мылом  None  None   None\n","1     у  попа  была  собака    он    её  любил"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["import pandas as pd\n","s=pd.Series([\"Мама мыла раму мылом\", \"У попа была собака он её любил\"],dtype=str)\n","# s = s.apply(lambda x: x.lower())\n","s=s.str.lower()\n","s=s.str.strip()\n","s\n","nn=set()\n","def growset(x):\n","    for w in x.split():\n","        nn.add(w)\n","s.apply(growset)        \n","df=pd.DataFrame(data=[(list(nn))],columns=[f'col{i}' for i in range(len(nn))])\n","df\n","\n","list(nn)\n","[(list(nn))]\n","s = s.str.split(\" \", expand=True)\n","s\n"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Note: you may need to restart the kernel to use updated packages.\n"]},{"name":"stderr","output_type":"stream","text":["ERROR: Could not find a version that satisfies the requirement morpher (from versions: none)\n","ERROR: No matching distribution found for morpher\n"]}],"source":["%pip install morpher \n"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[],"source":["import string\n","import pymorphy2\n","morpher = pymorphy2.MorphAnalyzer()\n","\n","def preprocess_txt(line):\n","    sw=[]\n","    # Почистим строку от пунктуации. Для этого пробежимся по каждому символу и проверим, не является ли он знаком пунктуации\n","    exclude = set(string.punctuation)\n","    spls = \"\".join(i for i in line.strip() if i not in exclude).split()\n","    # Лемматизируем все слова в нашем тексте\n","    spls = [morpher.parse(i.lower())[0].normal_form for i in spls]\n","    spls = [i for i in spls if i not in sw and i != \"\"]\n","    return spls"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"data":{"text/plain":["0                  [мама, мыло, рама, мыло]\n","1    [у, поп, быть, собака, он, её, любить]\n","dtype: object"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["import pandas as pd\n","s = pd.Series([\"Мама мыла раму мылом\", \"У попа была собака он её любил\"], dtype=\"string\")\n","s = s.apply(lambda x: preprocess_txt(x))\n","s"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[{"data":{"text/plain":["'мылом раму мыла мама'"]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["def preprocess_txt(line):\n","    line1=line.lower()\n","    line2=line1.split(\" \")\n","    line3=\" \".join(line2[::-1])\n","    return line3\n","s=s.apply(preprocess_txt)    \n","\n","preprocess_txt(\"Мама мыла раму мылом\")    "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def reverter(line):  return line.lower().split()[::-1]  \n","s[\"text\"] = s[\"text\"].apply(lambda x: reverter(x))\n","s"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting sklearn\n","  Using cached sklearn-0.0.tar.gz (1.1 kB)\n","  Preparing metadata (setup.py): started\n","  Preparing metadata (setup.py): finished with status 'done'\n","Collecting scikit-learn\n","  Downloading scikit_learn-1.1.2-cp39-cp39-win_amd64.whl (7.4 MB)\n","     ---------------------------------------- 7.4/7.4 MB 6.6 MB/s eta 0:00:00\n","Requirement already satisfied: numpy>=1.17.3 in c:\\users\\vsevolod.volkov\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-learn->sklearn) (1.23.2)\n","Collecting scipy>=1.3.2\n","  Downloading scipy-1.9.0-cp39-cp39-win_amd64.whl (38.6 MB)\n","     ---------------------------------------- 38.6/38.6 MB 4.8 MB/s eta 0:00:00\n","Collecting threadpoolctl>=2.0.0\n","  Using cached threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n","Requirement already satisfied: joblib>=1.0.0 in c:\\users\\vsevolod.volkov\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-learn->sklearn) (1.1.0)\n","Using legacy 'setup.py install' for sklearn, since package 'wheel' is not installed.\n","Installing collected packages: threadpoolctl, scipy, scikit-learn, sklearn\n","  Running setup.py install for sklearn: started\n","  Running setup.py install for sklearn: finished with status 'done'\n","Successfully installed scikit-learn-1.1.2 scipy-1.9.0 sklearn-0.0 threadpoolctl-3.1.0\n","Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["%pip install sklearn"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\vsevolod.volkov\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n","  warnings.warn(msg, category=FutureWarning)\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>awesome</th>\n","      <th>funny</th>\n","      <th>hate</th>\n","      <th>it</th>\n","      <th>like</th>\n","      <th>love</th>\n","      <th>movie</th>\n","      <th>nice</th>\n","      <th>one</th>\n","      <th>this</th>\n","      <th>was</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   awesome  funny  hate  it  like  love  movie  nice  one  this  was\n","0        0      1     0   1     1     0      1     0    0     1    0\n","1        0      0     1   0     0     0      1     0    0     1    0\n","2        1      0     0   1     1     0      0     0    0     1    1\n","3        0      0     0   1     0     1      0     1    1     0    0"]},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["documents = [\"I like this movie, it's funny.\", 'I hate this movie.', 'This was awesome! I like it.', 'Nice one. I love it.']\n","from sklearn.feature_extraction.text import CountVectorizer\n","import pandas as pd\n","\n","count_vectorizer = CountVectorizer()\n","\n","# Создаем the Bag-of-Words модель\n","bag_of_words = count_vectorizer.fit_transform(documents)\n","\n","# Отобразим Bag-of-Words модель как DataFrame\n","feature_names = count_vectorizer.get_feature_names()\n","pd.DataFrame(bag_of_words.toarray(), columns = feature_names)"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[{"data":{"text/plain":["<zip at 0x200b90fa140>"]},"execution_count":30,"metadata":{},"output_type":"execute_result"}],"source":["from nltk.util import ngrams\n","text = \"I like this movie, it's funny. I hate this movie. This was awesome! I like it. Nice one. I love it.\"\n","tokenized = text.split()\n","bigrams = ngrams(tokenized, 2)\n","bigrams"]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\vsevolod.volkov\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n","  warnings.warn(msg, category=FutureWarning)\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>awesome</th>\n","      <th>funny</th>\n","      <th>hate</th>\n","      <th>it</th>\n","      <th>like</th>\n","      <th>love</th>\n","      <th>movie</th>\n","      <th>nice</th>\n","      <th>one</th>\n","      <th>this</th>\n","      <th>was</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.000000</td>\n","      <td>0.571848</td>\n","      <td>0.000000</td>\n","      <td>0.365003</td>\n","      <td>0.450852</td>\n","      <td>0.000000</td>\n","      <td>0.450852</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.365003</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.702035</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.553492</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.448100</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.539445</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.344321</td>\n","      <td>0.425305</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.344321</td>\n","      <td>0.539445</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.345783</td>\n","      <td>0.000000</td>\n","      <td>0.541736</td>\n","      <td>0.000000</td>\n","      <td>0.541736</td>\n","      <td>0.541736</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    awesome     funny      hate        it      like      love     movie  \\\n","0  0.000000  0.571848  0.000000  0.365003  0.450852  0.000000  0.450852   \n","1  0.000000  0.000000  0.702035  0.000000  0.000000  0.000000  0.553492   \n","2  0.539445  0.000000  0.000000  0.344321  0.425305  0.000000  0.000000   \n","3  0.000000  0.000000  0.000000  0.345783  0.000000  0.541736  0.000000   \n","\n","       nice       one      this       was  \n","0  0.000000  0.000000  0.365003  0.000000  \n","1  0.000000  0.000000  0.448100  0.000000  \n","2  0.000000  0.000000  0.344321  0.539445  \n","3  0.541736  0.541736  0.000000  0.000000  "]},"execution_count":31,"metadata":{},"output_type":"execute_result"}],"source":["from sklearn.feature_extraction.text import TfidfVectorizer\n","import pandas as pd\n","document = [\"I like this movie, it's funny.\", 'I hate this movie.', 'This was awesome! I like it.', 'Nice one. I love it.']\n","tfidf_vectorizer = TfidfVectorizer()\n","values = tfidf_vectorizer.fit_transform(document)\n","# Show the Model as a pandas DataFrame\n","feature_names = tfidf_vectorizer.get_feature_names()\n","pd.DataFrame(values.toarray(), columns = feature_names)"]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[{"data":{"text/plain":["<4x16 sparse matrix of type '<class 'numpy.float64'>'\n","\twith 14 stored elements in Compressed Sparse Row format>"]},"execution_count":32,"metadata":{},"output_type":"execute_result"}],"source":["from sklearn.feature_extraction.text import HashingVectorizer\n","document = [\"I like this movie, it's funny.\", 'I hate this movie.', 'This was awesome! I like it.', 'Nice one. I love it.']\n","vectorizer = HashingVectorizer(n_features=2**4)\n","values = vectorizer.fit_transform(document)\n","values"]}],"metadata":{"colab":{"name":"TextPreprocessing.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3.9.13 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"},"vscode":{"interpreter":{"hash":"20e0411d6d37670f7ff2fe9b9e2c31fabc9d5997a01474d14773f9d8fd25341d"}}},"nbformat":4,"nbformat_minor":0}

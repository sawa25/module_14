{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# conda install -c conda-forge python-annoy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "1LJvRpgiP5Oe"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'gensim'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\User\\SkillFactory\\GitHub\\module_14\\ChatBotPractice.ipynb Ячейка 1\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/User/SkillFactory/GitHub/module_14/ChatBotPractice.ipynb#W0sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpymorphy2\u001b[39;00m \u001b[39mimport\u001b[39;00m MorphAnalyzer\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/User/SkillFactory/GitHub/module_14/ChatBotPractice.ipynb#W0sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mstop_words\u001b[39;00m \u001b[39mimport\u001b[39;00m get_stop_words\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/User/SkillFactory/GitHub/module_14/ChatBotPractice.ipynb#W0sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgensim\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m \u001b[39mimport\u001b[39;00m Word2Vec\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/User/SkillFactory/GitHub/module_14/ChatBotPractice.ipynb#W0sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/SkillFactory/GitHub/module_14/ChatBotPractice.ipynb#W0sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtqdm\u001b[39;00m \u001b[39mimport\u001b[39;00m tqdm_notebook\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'gensim'"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import string\n",
        "import annoy\n",
        "\n",
        "from pymorphy2 import MorphAnalyzer\n",
        "from stop_words import get_stop_words\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "import numpy as np\n",
        "from tqdm import tqdm_notebook\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DrdA0HmPP5Oj"
      },
      "source": [
        "Предобработаем ответы mail.ru из файла: к каждому вопросу присоединим 1 ответ и запишем в файл на будущее. Это позволит нам сэкономить время и ресурсы при дальнейшем препроцессинге текста"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ul4dgvpnP5Ol"
      },
      "outputs": [],
      "source": [
        "question = None\n",
        "written = False\n",
        "\n",
        "#Мы идем по всем записям, берем первую строку как вопрос\n",
        "# и после знака --- находим ответ\n",
        "with open(\"prepared_answers.txt\", \"w\") as fout:\n",
        "    with open(\"Otvety.txt\", \"r\") as fin:\n",
        "        for line in tqdm_notebook(fin):\n",
        "            if line.startswith(\"---\"):\n",
        "                written = False\n",
        "                continue\n",
        "            if not written and question is not None:\n",
        "                fout.write(question.replace(\"\\t\", \" \").strip() + \"\\t\" + line.replace(\"\\t\", \" \"))\n",
        "                written = True\n",
        "                question = None\n",
        "                continue\n",
        "            if not written:\n",
        "                question = line.strip()\n",
        "                continue"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hw5tHi8bP5Om"
      },
      "source": [
        "Теперь нам нужно предобработать текст, чтобы обучить word2vec и получить эмбеддинги. Удаляем знаки препинания и делаем лемматизацию"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ky7bZJ9xP5On"
      },
      "outputs": [],
      "source": [
        "def preprocess_txt(line):\n",
        "    spls = \"\".join(i for i in line.strip() if i not in exclude).split()\n",
        "    spls = [morpher.parse(i.lower())[0].normal_form for i in spls]\n",
        "    spls = [i for i in spls if i not in sw and i != \"\"]\n",
        "    return spls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s_Ra2xeLP5On"
      },
      "outputs": [],
      "source": [
        "sentences = []\n",
        "\n",
        "morpher = MorphAnalyzer()\n",
        "sw = set(get_stop_words(\"ru\"))\n",
        "exclude = set(string.punctuation)\n",
        "c = 0\n",
        "\n",
        "with open(\"Otvety.txt\", \"r\") as fin:\n",
        "    for line in tqdm_notebook(fin):\n",
        "        spls = preprocess_txt(line)\n",
        "        sentences.append(spls)\n",
        "        c += 1\n",
        "        if c > 500000:\n",
        "            break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ZiMlSWbP5Oo"
      },
      "outputs": [],
      "source": [
        "# Обучим модель word2vec на наших вопросах\n",
        "sentences = [i for i in sentences if len(i) > 2]\n",
        "model = Word2Vec(sentences=sentences, vector_size=100, min_count=1, window=5)\n",
        "model.save(\"w2v_model\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2i0XxCAuP5Op"
      },
      "source": [
        "Теперь нам нужно сложить в индекс все вопросы. Используем библиотеку annoy. Проходимся по всем ответам, считаем, что вектор предложения - сумма word2vecов слов, которые входят в него (конечно же усредненная)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wwW3CG8tP5Op"
      },
      "outputs": [],
      "source": [
        "index = annoy.AnnoyIndex(100 ,'angular')\n",
        "\n",
        "index_map = {}\n",
        "counter = 0\n",
        "\n",
        "with open(\"prepared_answers.txt\", \"r\") as f:\n",
        "    for line in tqdm_notebook(f):\n",
        "        n_w2v = 0\n",
        "        spls = line.split(\"\\t\")\n",
        "        index_map[counter] = spls[1]\n",
        "        question = preprocess_txt(spls[0])\n",
        "        vector = np.zeros(100)\n",
        "        for word in question:\n",
        "            if word in model.wv:\n",
        "                vector += model.wv[word]\n",
        "                n_w2v += 1\n",
        "        if n_w2v > 0:\n",
        "            vector = vector / n_w2v\n",
        "        index.add_item(counter, vector)\n",
        "            \n",
        "        counter += 1\n",
        "\n",
        "index.build(10)\n",
        "index.save('speaker.ann')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "snKnXkaQP5Oq"
      },
      "source": [
        "Теперь остается реализовать метод, который получит на вход вопрос и найдет ответ к нему!\n",
        "Мы препроцессим вопрос, находим ближайший вопрос и выбираем ответ на ближайший вопрос."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mPSLEsqWP5Or"
      },
      "outputs": [],
      "source": [
        "def find_answer(question):\n",
        "    preprocessed_question = preprocess_txt(question)\n",
        "    n_w2v = 0\n",
        "    vector = np.zeros(100)\n",
        "    for word in preprocessed_question:\n",
        "        if word in model.wv:\n",
        "            vector += model.wv[word]\n",
        "            n_w2v += 1\n",
        "    if n_w2v > 0:\n",
        "        vector = vector / n_w2v\n",
        "    answer_index = index.get_nns_by_vector(vector, 1)\n",
        "    return index_map[answer_index[0]]"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "ChatBotPractice.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.13 ('conda39')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "nteract": {
      "version": "0.28.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "b5765786a938375815638974de732fd28cd17f3102640a7cecb4c7fa045c959e"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
